# Configuration for the AI Model Pipeline

model:
  base_model_name: "llava-hf/llava-1.5-7b-hf"
  fine_tuned_path: "./artifacts/fine_tuned_model"
  quantized_path: "./artifacts/quantized_model"
  coreml_output_path: "./artifacts/AuraModel.mlmodel"

data:
  dataset_name: "pcuenq/oxford-pets"
  local_path: "./data"

training:
  num_epochs: 3
  learning_rate: 1e-5
  batch_size_per_device: 4
  output_dir: "./artifacts/training_output"

optimization:
  quantization_type: "int8"