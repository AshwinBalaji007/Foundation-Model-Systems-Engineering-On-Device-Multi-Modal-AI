# Configuration for the AI Model Pipeline (BLIP Model)

model:
  # --- THE CHANGE ---
  base_model_name: "Salesforce/blip-image-captioning-large"
  
  fine_tuned_path: "./artifacts/blip_finetuned.pth"
  quantized_path: "./artifacts/blip_quantized.pth"
  coreml_output_path: "./artifacts/AuraModel.mlmodel"

data:
  dataset_name: "pcuenq/oxford-pets"

training:
  num_epochs: 1
  learning_rate: 5e-5 # A common starting learning rate for fine-tuning
  batch_size_per_device: 8 # We can use a larger batch size with a smaller model